# -*- coding: utf-8 -*-
import numpy as np
from typing import Iterable, Optional, List, Dict, Any, Tuple
import json
import os
import asyncio
import logging
from openai import OpenAI, AsyncOpenAI
from numpy.linalg import norm

logger = logging.getLogger(__name__)


class Node:
    def __init__(
        self,
        name: str,
        description: str,
        embedding: Optional[np.ndarray] = None,
        is_directory: bool = False,
        children: Optional[set] = None,
        parent: Optional["Node"] = None,
        allow_split: bool = True,
        **kwargs: Any,
    ) -> None:
        """Initialize node
        Args:
            name: Node name
            description: Node description
            embedding: Node's embedding vector
            allow_split: Whether to allow splitting this node, default True
        """
        self.name = name
        self.description = description
        self.embedding = embedding
        self.is_directory = is_directory
        self.parent: Node | None = parent
        self.children: set[Node] = children if children else set()
        self.allow_split = allow_split

    def get_node_stats(self) -> Dict[str, Any]:
        """Get statistics of current node

        Returns:
            dict: Dictionary containing the following information
                - children_count: Number of direct child nodes
                - total_descendants: Total number of descendant
                nodes (calculated recursively)
                - depth: Depth from root node to current node
                - subtree_depth: Subtree depth with current node as root
        """
        return {
            "children_count": len(self.children),
            "total_descendants": self._count_total_descendants(),
            "depth": self._calculate_depth_from_root(),
            "subtree_depth": self._calculate_subtree_depth(),
        }

    def _count_total_descendants(self) -> int:
        """Recursively calculate total number of descendant nodes"""
        total = len(self.children)
        for child in self.children:
            total += child._count_total_descendants()
        return total

    def _calculate_depth_from_root(self) -> int:
        """Calculate depth from root node to current node"""
        depth = 0
        current = self.parent
        while current:
            depth += 1
            current = current.parent
        return depth

    def _calculate_subtree_depth(self) -> int:
        """Calculate subtree depth with current node as root"""
        if not self.children:
            return 0

        max_depth = 0
        for child in self.children:
            child_depth = 1 + child._calculate_subtree_depth()
            max_depth = max(max_depth, child_depth)
        return max_depth

    def visualize_tree_with_stats(
        self,
        debug: bool = False,
        bfs_depth: float = float("inf"),
        description: bool = True,
        save_path: str = "",
    ) -> str:
        """Generate tree visualization with statistics

        Args:
            debug: Whether to use emoji icons
            bfs_depth: Maximum depth to display
            description: Whether to display description information
            save_path: Save path
        """
        count = 0

        def print_tree_with_stats(
            node: Node,
            prefix: str = "",
            is_last: bool = True,
            is_root: bool = False,
            depth: int = -1,
        ) -> str:
            nonlocal count
            if depth > bfs_depth:
                return ""
            count += 1
            sub_str = ""

            # Get node statistics
            stats = node.get_node_stats()

            if description:
                n_description = node.description.strip().replace("\n", "\t")
                n_description = f"description: {n_description}"
            else:
                n_description = ""

            # Statistics string
            stats_str = f" [Children:{stats['children_count']},"
            f" Descendants:{stats['total_descendants']}, "
            f"Depth:{stats['depth']}, Subtree depth:{stats['subtree_depth']}]"

            if is_root:
                sub_str += f"name: {node.name},  {n_description}{stats_str}\n"
            else:
                connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
                node_type = "class" if node.is_directory else "tool"
                if debug:
                    node_type = "üìÅ" if node.is_directory else "üîß"

                sub_str += f"{prefix}{connector}{node_type}"
                f" name: {node.name}  {n_description}{stats_str}\n"

            new_prefix = prefix
            if not is_root:
                new_prefix = prefix + ("    " if is_last else "‚îÇ   ")

            children = node.children
            for i, child in enumerate(children):
                is_child_last = i == len(children) - 1
                sub_str += print_tree_with_stats(
                    child,
                    new_prefix,
                    is_child_last,
                    depth=depth + 1,
                )
            return sub_str

        all_str = print_tree_with_stats(self, is_root=True, depth=0)
        if debug:
            print(all_str)
        if save_path:
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(all_str)
        print(f"Current total tree nodes: {count}")
        return all_str

    def print_tree_stats_summary(self) -> None:
        """Print tree statistics summary"""

        def collect_all_stats(
            node: Node,
            all_stats: Optional[List[Dict[str, Any]]] = None,
        ) -> List[Dict[str, Any]]:
            if all_stats is None:
                all_stats = []
            if not node.is_directory:
                return all_stats
            stats = node.get_node_stats()
            stats["name"] = node.name
            stats["is_directory"] = node.is_directory
            all_stats.append(stats)

            for child in node.children:
                collect_all_stats(child, all_stats)

            return all_stats

        all_stats = collect_all_stats(self)

        print("=" * 60)
        print("Tree Status Statistics Summary")
        print("=" * 60)
        print(f"Total nodes: {len(all_stats)}")
        print(f"Max depth: {max(s['depth'] for s in all_stats)}")
        print("-" * 60)
        print("Detailed statistics for each node:")
        print("-" * 60)

        for stats in all_stats:
            node_type = "üìÅ" if stats["is_directory"] else "üîß"
            print(
                f"{node_type} {stats['name']:<20} |"
                f" Children:{stats['children_count']:>3} |"
                f" Descendants:{stats['total_descendants']:>3} |",
            )

        print("=" * 60)

    def to_dict(self) -> Dict[str, Any]:
        """Convert node to dictionary representation"""
        # Ensure no circular references - don't save parent references
        result = {
            "name": self.name,
            "description": self.description,
            "embedding": (
                self.embedding.tolist()
                if isinstance(self.embedding, np.ndarray)
                else self.embedding
            ),
            "is_directory": self.is_directory,
            "allow_split": self.allow_split,
            "children": [child.to_dict() for child in self.children],
        }
        return result

    def __str__(self) -> str:
        """String representation of current node and child nodes"""
        description = self.description.strip()
        if self.is_directory:
            return (
                f"tool class(name='{self.name}', description='{description}')"
            )
        else:
            return f"tool(name='{self.name}', description='{description}')"

    def visualize_tree(
        self,
        debug: bool = False,
        leaf: bool = True,
        bfs_depth: float = float("inf"),
        description: bool = True,
        save_path: str = "",
    ) -> str:
        """Generate tree visualization (level order), display subtree"""
        count = 0

        def print_tree(
            node: "Node",
            prefix: str = "",
            is_last: bool = True,
            is_root: bool = False,
            depth: int = -1,
        ) -> str:
            nonlocal count
            if depth > bfs_depth:
                return ""
            count += 1
            sub_str = ""
            if description:
                n_description = node.description.strip().replace("\n", "\t")
                n_description = f"description: {n_description}"
            else:
                n_description = ""
            if is_root:
                sub_str += f"name: {node.name},  {n_description}\n"
            else:
                connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
                node_type = "class" if node.is_directory else "tool"
                if debug:
                    node_type = "üìÅ" if node.is_directory else "üîß"

                sub_str += f"{prefix}{connector}{node_type}"
                f" name: {node.name}  {n_description}\n"

            new_prefix = prefix
            if not is_root:
                new_prefix = prefix + ("    " if is_last else "‚îÇ   ")

            children = node.children
            # print(node,children)
            for i, child in enumerate(children):
                is_child_last = i == len(children) - 1
                sub_str += print_tree(
                    child,
                    new_prefix,
                    is_child_last,
                    depth=depth + 1,
                )
            return sub_str

        # print('---------',self.to_dict())
        all_str = print_tree(self, is_root=True, depth=0)
        if debug:
            print(all_str)
        if save_path:
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(all_str)
        print("Current tree nodes", count)
        return all_str


class Tree:
    def __init__(
        self,
        max_items_per_node: int = 5,
        batch_size: int = 10,
        embedding_cache_path: Optional[str] = None,
        base_url: Optional[str] = None,
        openai_api_key: Optional[str] = None,
        model: Optional[str] = None,
        embed_model: Optional[str] = None,
    ) -> None:
        """Initialize tree structure

        Args:
            max_items_per_node: Maximum number of sub-items each node
            can contain, split if exceeded
            batch_size: Batch size for batch retrieval of embedding vectors
            embedding_cache_path: Embedding vector cache file path,
            no cache used if None
            base_url: API base URL
            openai_api_key: Openai format key
            model: Model name to use
            embed_model: Model name for generating embeddings
        """
        self.max_items_per_node = max_items_per_node
        self.batch_size = batch_size
        # Root node is a directory node, does not store actual tools
        self.root = Node("root", "Root node of tool tree", is_directory=True)
        self._name_to_node = {"root": self.root}

        # Embedding vector cache
        self.embedding_cache_path = embedding_cache_path or os.path.join(
            os.getcwd(),
            "embedding_cache.json",
        )
        self.embedding_cache = {}
        self._load_embedding_cache()

        self.openai_api_key = openai_api_key or os.getenv("DS_AK")
        self.base_url = (
            base_url or "https://dashscope.aliyuncs.com/compatible-mode/v1"
        )
        self.model = model or "qwen3-235b-a22b"
        self.embed_model = embed_model or "text-embedding-v3"

        if not self.openai_api_key:
            raise ValueError(
                "‚ùå OpenAI API Key not found, "
                "please set AK in .env file or pass openai_api_key parameter",
            )

        self.client = OpenAI(
            api_key=self.openai_api_key,
            base_url=self.base_url,
        )
        self.ayncclient = AsyncOpenAI(
            api_key=self.openai_api_key,
            base_url=self.base_url,
        )
        self.tree_emb = []  # Used to store tree embeddings
        self.tree_node = []

    def _load_embedding_cache(self) -> None:
        """Load embedding vector cache from file"""
        try:
            if os.path.exists(self.embedding_cache_path):
                with open(
                    self.embedding_cache_path,
                    "r",
                    encoding="utf-8",
                ) as f:
                    cache_data = json.load(f)
                    # Convert lists back to numpy arrays
                    for text, embedding in cache_data.items():
                        if embedding:  # Ensure it's not None
                            self.embedding_cache[text] = np.array(embedding)
                print(
                    f"‚úÖ Loaded cache from {self.embedding_cache_path}",
                )
        except Exception as e:
            print(f"‚ùå Error loading embedding vector cache: {e}")
            self.embedding_cache = {}

    def _save_embedding_cache(self) -> None:
        """Save embedding vector cache to file"""
        try:
            cache_to_save = {}
            emb_cache = self.embedding_cache
            for text, embedding in emb_cache.items():
                if embedding is not None:
                    if isinstance(embedding, np.ndarray):
                        cache_to_save[text] = embedding.tolist()
                    else:
                        cache_to_save[text] = embedding

            with open(self.embedding_cache_path, "w", encoding="utf-8") as f:
                json.dump(cache_to_save, f, ensure_ascii=False)
            print(
                f"Saved {len(cache_to_save)} embedding to"
                f" {self.embedding_cache_path}",
            )
        except Exception as e:
            print(f"‚ùå Error saving embedding vector cache: {e}")

    def get_embedding(self, text: str) -> Optional[np.ndarray]:
        """Get text embedding vector, prioritize getting from cache"""
        # Check cache
        if text in self.embedding_cache:
            return self.embedding_cache[text]

        try:
            response = self.client.embeddings.create(
                model=self.embed_model,
                input=text,
            )
            embedding = np.array(response.data[0].embedding)

            # Save to cache
            self.embedding_cache[text] = embedding
            return embedding
        except Exception as e:
            print(f"Error getting embedding: {e}")
            return None

    def ask_llm(
        self,
        messages: Iterable,
        model: str = "qwen-plus-latest",
        **kwargs: Any,
    ) -> str:
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                **kwargs,
            )
            return response.choices[0].message.content
        except Exception as e:
            print(e)
            return ""

    async def ask_llm_async(
        self,
        messages: Iterable,
        model: str = "qwen-plus-latest",
        extra_body: Dict[str, Any] = {"enable_thinking": False},
        **kwargs: Any,
    ) -> str:
        """Async call to LLM interface"""
        try:
            response = await self.ayncclient.chat.completions.create(
                model=model,
                messages=messages,
                extra_body=extra_body,
                **kwargs,
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"Error calling LLM: {e}")
            return ""

    async def get_embeddings_batch(
        self,
        texts: List[str],
        batch_size: Optional[int] = None,
    ) -> np.ndarray:
        """Batch get text embedding vectors,
        supporting concurrent processing and caching

        Args:
            texts: List of texts to get embedding vectors for
            batch_size: Number of texts to process per batch,
            defaults to batch_size set during instantiation

        Returns:
            numpy array containing all embedding vectors
        """
        if batch_size is None:
            batch_size = self.batch_size

        all_embeddings = []
        texts_to_process = []
        text_indices = []

        # First check if there are existing embedding vectors in cache
        for i, text in enumerate(texts):
            if text in self.embedding_cache:
                # Use cached embedding vector
                all_embeddings.append(self.embedding_cache[text])
            else:
                # Need to re-obtain embedding vector
                texts_to_process.append(text)
                text_indices.append(i)
                all_embeddings.append(None)

        if texts_to_process:
            print(
                f"‚úÖ Found {len(texts) - len(texts_to_process)}/{len(texts)}"
                " embedding vectors from cache",
            )
            print(f"‚è≥ Need to process {len(texts_to_process)} new texts...")

            semaphore = asyncio.Semaphore(3)  # Limit concurrent requests

            async def process_batch(
                batch_texts: list,
                batch_indices: list,
            ) -> Tuple[list, List[int]]:
                async with semaphore:
                    try:
                        response = await asyncio.to_thread(
                            self.client.embeddings.create,
                            model=self.embed_model,
                            input=batch_texts,
                        )
                        embeddings = [data.embedding for data in response.data]

                        # Update cache
                        for i, embedding in enumerate(embeddings):
                            if embedding is not None:
                                text = batch_texts[i]
                                self.embedding_cache[text] = embedding

                        return embeddings, batch_indices
                    except Exception as e:
                        print(f"‚ùå Error getting embedding: {e}")
                        # Return empty vectors as fallback
                        return [None] * len(batch_texts), batch_indices

            # Batch processing
            batches = []
            for i in range(0, len(texts_to_process), batch_size):
                batch_texts = texts_to_process[i : i + batch_size]
                batch_indices = text_indices[i : i + batch_size]
                batches.append(process_batch(batch_texts, batch_indices))

            print(
                f"üìä Split into {len(batches)} batches for "
                "concurrent embedding processing...",
            )
            results = await asyncio.gather(*batches)

            for batch_result, batch_indices in results:
                for j, embedding in enumerate(batch_result):
                    original_idx = batch_indices[j]
                    all_embeddings[original_idx] = embedding

            # Save cache after processing
            self._save_embedding_cache()

        # Handle possible None values
        dim = 1536  # Default embedding dimension
        if any(e is not None for e in all_embeddings):
            for e in all_embeddings:
                if e is not None:
                    dim = len(e)
                    break
        for i, emb in enumerate(all_embeddings):
            if emb is None:
                all_embeddings[i] = np.zeros(dim)

        return np.array(all_embeddings)

    def get_node_by_name(self, name: str) -> Node | None:
        """Find node by node name

        Args:
            name: Node name

        Returns:
            Found node, returns None if not exists
        """
        if self._name_to_node.get(name, None):
            return self._name_to_node[name]
        else:
            emb = self.get_embedding(name)
            if emb is not None:
                score = self.cosine_similarity(emb)
                new_node = self.tree_node[score.argmax()]
                print(
                    f"Node {name} does not exist",
                    f"Using embedding to get: {new_node}",
                )
                if self._name_to_node.get(new_node, None):
                    return self._name_to_node[new_node]

            return None

    def cosine_similarity(self, vec1: np.ndarray) -> np.ndarray:

        # Handle zero vector cases
        score = np.array(vec1) @ np.array(self.tree_emb).T

        # Return cosine similarity
        return score

    def add_child(self, child: Node, parent: Node) -> None:
        """Add child node to parent node, only update parent-child
        relationship without any operations

        Args:
            child: Child node
            parent: Parent node
        """
        # Prevent circular references: check if parent is a descendant of child
        if self._would_create_cycle(child, parent):
            logger.warning(
                "Detected potential circular reference:"
                f" cannot add '{child.name}' as child of '{parent.name}'",
            )
            return

        if child.parent:
            child.parent.children.discard(child)
        self._name_to_node[child.name] = child
        parent.children.add(child)

        child.parent = parent

    def _would_create_cycle(self, child: Node, parent: Node) -> bool:
        """Check if adding child node would create circular reference

        Args:
            child: Child node to add
            parent: Target parent node

        Returns:
            Returns True if would create circular reference
        """
        # Check if parent is a descendant of child
        current = parent
        visited = set()

        while current:
            if current in visited:
                return True  # Detected cycle
            if current == child:
                return True  # parent is child's descendant, would create cycle
            visited.add(current)
            current = current.parent

        return False

    def insert_node(self, node_data: dict) -> None:
        """Insert node into tree and handle possible node splitting

        Args:
            node_data: Dictionary containing node information
            (name, description, embedding, etc.)
        """
        node = Node(**node_data)
        # New node is a leaf node, stores actual tools
        self._name_to_node[node.name] = node

        # Find the most suitable directory node for insertion
        best_dir_node, similarity = self._find_best_directory(node)
        # Insert node into directory

        best_dir_node.children.add(node)

        # Check if directory needs splitting
        not_dir_node = [
            child for child in best_dir_node.children if not child.is_directory
        ]
        if len(not_dir_node) > self.max_items_per_node:
            self._split_directory(best_dir_node)

    def _find_best_directory(self, node: Node) -> Tuple[Node, float]:
        """Find the most suitable directory for inserting new node

        Returns: (directory node, similarity score)
        """
        best_directory: Node = self.root  # Default to root node
        best_similarity = 0.0

        def traverse(directory: Node, node: Node) -> None:
            nonlocal best_directory, best_similarity

            # Only calculate similarity for directory nodes
            if (
                directory.is_directory
                and directory.embedding is not None
                and node.embedding is not None
            ):
                similarity = self._cosine_similarity(
                    directory.embedding,
                    node.embedding,
                )

                if (
                    similarity > best_similarity
                    and len(directory.children) < self.max_items_per_node
                ):
                    best_similarity = similarity
                    best_directory = directory

            # Recursively traverse subdirectories
            for child in directory.children:
                if child.is_directory:
                    traverse(child, node)

        traverse(self.root, node)
        return best_directory, best_similarity

    def _cluster_nodes(self, nodes: set[Node]) -> set[Node]:
        """Cluster nodes into n groups

        Use embedding-based clustering method

        Args:
            nodes: List of nodes to cluster
            n_clusters: Number of clusters

        Returns:
            List containing n node lists
        """
        # If nodes don't have embedding, use simple grouping method
        return nodes

    def _split_directory(self, directory: Node) -> None:
        """Split directory node containing too many items

        Args:
            directory: Directory node that needs to be split
        """
        if not directory.is_directory:
            return

        # Check if node allows splitting
        if not directory.allow_split:
            return

        # Get non-directory child nodes
        non_dir_children = [
            child for child in directory.children if not child.is_directory
        ]

        if len(non_dir_children) <= self.max_items_per_node:
            return

        # Simple split: divide child nodes into two groups
        mid_point = len(non_dir_children) // 2
        group1 = non_dir_children[:mid_point]
        group2 = non_dir_children[mid_point:]

        # Create two new subdirectories
        subdir1 = Node(
            name=f"{directory.name}_subdir1",
            description=f"{directory.description} - Subdirectory 1",
            embedding=directory.embedding,
            is_directory=True,
            parent=directory,
        )

        subdir2 = Node(
            name=f"{directory.name}_subdir2",
            description=f"{directory.description} - Subdirectory 2",
            embedding=directory.embedding,
            is_directory=True,
            parent=directory,
        )

        # Reassign child nodes to new subdirectories
        for child in group1:
            directory.children.discard(child)
            subdir1.children.add(child)
            child.parent = subdir1

        for child in group2:
            directory.children.discard(child)
            subdir2.children.add(child)
            child.parent = subdir2

        # Add new subdirectories to original directory
        directory.children.add(subdir1)
        directory.children.add(subdir2)

        # Update name mapping
        self._name_to_node[subdir1.name] = subdir1
        self._name_to_node[subdir2.name] = subdir2

    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """Calculate cosine similarity between two vectors"""
        if vec1 is None or vec2 is None:
            return 0.0
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        if norm1 == 0 or norm2 == 0:
            return 0.0
        return dot_product / (norm1 * norm2)

    def to_dict(self) -> Dict[str, Any]:
        """Return dictionary representation of entire tree"""
        return self.root.to_dict()

    def to_pretty_json(self) -> str:
        """Return formatted JSON string"""
        return json.dumps(self.root.to_dict(), indent=2, ensure_ascii=False)

    def get_tools_count(self) -> int:
        """Get actual number of tools in tree"""
        count = 0

        def count_tools(node: Node) -> None:
            nonlocal count
            if not node.is_directory:
                count += 1
            for child in node.children:
                count_tools(child)

        count_tools(self.root)
        return count

    def get_directory_stats(self) -> Dict[str, Any]:
        """Get directory statistics"""
        stats = {
            "total_directories": 0,
            "total_tools": 0,
            "max_depth": 0,
            "avg_tools_per_dir": 0.0,
        }

        dir_counts = []

        def traverse(node: Node, depth: int = 0) -> None:
            if node.is_directory:
                stats["total_directories"] += 1
                tool_count = 0
                for child in node.children:
                    if not child.is_directory:
                        tool_count += 1
                if tool_count > 0:  # Only count directories with tools
                    dir_counts.append(tool_count)

                # Update maximum depth
                stats["max_depth"] = max(stats["max_depth"], depth)

                # Recursively process subdirectories
                for child in node.children:
                    if child.is_directory:
                        traverse(child, depth + 1)
            else:
                stats["total_tools"] += 1

        traverse(self.root)

        if dir_counts:
            stats["avg_tools_per_dir"] = sum(dir_counts) / len(dir_counts)

        return stats

    def save_to_file(self, filepath: str) -> bool:
        """Save tree structure to file"""
        tree_data = {
            "tree": self.to_dict(),
            "max_items_per_node": self.max_items_per_node,
        }

        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(tree_data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"Error saving tree structure: {e}")
            return False

    @classmethod
    def load_from_file(cls, filepath: str) -> Optional["Tree"]:
        """Load tree structure from file"""
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                tree_data = json.load(f)

            max_items_per_node = tree_data.get("max_items_per_node", 5)
            tree = cls(max_items_per_node=max_items_per_node)

            # Recursively build tree
            def build_tree(
                node_dict: dict,
                parent: Node | None = None,
            ) -> Node:
                # Create node
                embedding = node_dict.get("embedding")
                if embedding is not None:
                    embedding = np.array(embedding)

                node = Node(
                    name=node_dict.get("name", ""),
                    description=node_dict.get("description", ""),
                    embedding=embedding,
                    is_directory=node_dict.get("is_directory", False),
                    allow_split=node_dict.get("allow_split", True),
                    parent=parent,
                )

                # Add to name index
                tree._name_to_node[node.name] = node

                # Recursively add child nodes
                for child_dict in node_dict.get("children", []):
                    child = build_tree(child_dict, node)
                    node.children.add(child)

                return node

            # Build root node and its subtree
            tree.root = build_tree(tree_data["tree"])

            return tree

        except Exception as e:
            print(f"Error loading tree structure: {e}")
            return None

    def clean_node(self, node: Node | None) -> None:
        """Clean up nodes"""
        # Remove empty child nodes
        if not node or not node.is_directory:
            return
        children = node.children
        if node.is_directory and not children:
            if node.parent:
                node.parent.children.discard(node)
            node.parent = None
            # Delete node
            if node.name in self._name_to_node:
                del self._name_to_node[node.name]

        elif len(children) > 1:
            for child in list(children):
                if child.is_directory:
                    self.clean_node(child)

        else:
            while len(children) == 1 and list(children)[0].is_directory:
                # If only one child node, promote child node directly
                if list(children)[0].name in self._name_to_node:
                    del self._name_to_node[list(children)[0].name]
                node.children.discard(list(children)[0])
                children = list(children)[0].children

            children_to_add = list(children)
            for child in children_to_add:
                self.add_child(child, node)
                self.clean_node(child)
